{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbab4ef-2033-4d4e-b469-454754e14d12",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## MLE\n",
    "### Unigram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b0eacf-bc16-4b57-ab8a-10f6dda7244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ['A', 'B', 'A', 'B', 'B', 'C', 'A', 'B', 'A', 'A', 'B', 'C', 'A', 'C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b2e51c-3854-41d6-b33a-ac0980526dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the thetha optimun for A is: 0.42857142857142855\n",
      "the thetha optimun for B is: 0.35714285714285715\n",
      "the thetha optimun for C is: 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "theta_a_op = seq.count('A')/len(seq)\n",
    "theta_b_op = seq.count('B')/len(seq)\n",
    "theta_c_op = seq.count('C')/len(seq)\n",
    "\n",
    "print(f\"the thetha optimun for A is: {theta_a_op}\")\n",
    "print(f\"the thetha optimun for B is: {theta_b_op}\")\n",
    "print(f\"the thetha optimun for C is: {theta_c_op}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6b88d-ca2d-4bf9-8736-9c6298eaec72",
   "metadata": {},
   "source": [
    "Using the MLE estimate of $\\theta$ on $\\mathcal{D}$, which of the following sequences is most likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc8f168-bb0d-43b9-9ab5-6687d473a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03279883381924198 0.04555393586005831 0.05466472303206997 0.039358600583090375\n"
     ]
    }
   ],
   "source": [
    "seq_1 = theta_a_op*theta_b_op*theta_c_op\n",
    "seq_2 = theta_b_op*theta_b_op*theta_b_op\n",
    "seq_3 = theta_a_op*theta_b_op*theta_b_op\n",
    "seq_4 = theta_a_op*theta_a_op*theta_c_op\n",
    "\n",
    "print(seq_1, seq_2, seq_3, seq_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb6940-e4e6-4a93-9ee7-138f02cb3c34",
   "metadata": {},
   "source": [
    "### Bigram Model 2\n",
    "\n",
    "Which of the following represents the MLE for the conditional probability $p(w_2 \\mid w_1)$\n",
    "\n",
    "#### Bigram model — basic idea\n",
    "\\begin{equation}\n",
    "P\\left(w_1, \\ldots, w_T\\right) \\approx \\prod_{t=1}^T P\\left(w_t \\mid w_{t-1}\\right),\n",
    "\\end{equation}\n",
    "where by convention $w_0$ is a special start token ⟨s⟩.\n",
    "So the conditional probability you need to model is $p(w_i \\mid w_{i-1})$\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{P}_{\\mathrm{MLE}}\\left(w_i \\mid w_{i-1}\\right)=\\frac{c\\left(w_{i-1}, w_i\\right)}{c\\left(w_{i-1}\\right)} .\n",
    "\\end{equation}\n",
    "\n",
    "we obtained $w_{i-1}$ by summing over (i.e. marginalizing out) all possible continuations $w$ in the joint counts $c\\left(w_{i-1}, w\\right)$\n",
    "\n",
    "\\begin{equation}\n",
    "c\\left(w_{i-1}\\right)=\\sum_w c\\left(w_{i-1}, w\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{P}_{\\mathrm{MLE}}\\left(w_i \\mid w_{i-1}\\right)=\\frac{c\\left(w_{i-1}, w_i\\right)}{\\sum_w c\\left(w_{i-1}, w\\right)} .\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e382011-e975-45ab-8ba2-b78045e182ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_aa = 1/6\n",
    "P_ba = 4/6\n",
    "P_cb = 2/5\n",
    "P_bc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba397ce3-7c29-476e-81f0-b194086a5559",
   "metadata": {},
   "source": [
    "The answer is zero due to the P_bc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0744f-4c2a-4d76-88f9-dd08f1434b30",
   "metadata": {},
   "source": [
    "## EM Algorithm\n",
    "### Likelihood Function\n",
    "Consider the following mixture of two Gaussians:\n",
    "\\begin{equation}\n",
    "p(x; \\theta ) = \\pi _1 \\mathcal{N}(x; \\mu _1, \\sigma _1^2) + \\pi _2\\mathcal{N}(x; \\mu _2, \\sigma _2^2)\n",
    "\\end{equation}\n",
    "\n",
    "This mixture has parameters $\\theta = \\{ \\pi _1, \\pi _2, \\mu _1, \\mu _2, \\sigma _1^2, \\sigma _2^2\\}$\n",
    "We initialize $\\theta$ as $\\theta _0 = \\{ 0.5, 0.5, 6, 7, 1, 4\\}$.\n",
    "\n",
    "We have a dataset $\\mathcal{D}$ with the following samples of\n",
    "\\begin{equation}\n",
    "x: x^{(0)}=-1, x^{(1)}=0, x^{(2)}=4, x^{(3)}=5, x^{(4)}=6 .\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7939274-4c95-4e8c-8efb-cfd00416d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-1, 0, 4, 5, 6]\n",
    "pi = [0.5, 0.5]\n",
    "mu = [6, 7]\n",
    "sigma_2 = [1, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d7c7a-26d9-4f24-8e19-a968804180e5",
   "metadata": {},
   "source": [
    "What is the log-likelihood of the data $l(\\mathcal{D}; \\theta )$ given the initial setting of $\\theta$?\n",
    "\\begin{equation}\n",
    "l(\\mathcal{D} ; \\theta)=\\sum_{i=0}^{N-1} \\log \\left(\\pi_1 \\mathcal{N}\\left(x^{(i)} ; \\mu_1, \\sigma_1^2\\right)+\\pi_2 \\mathcal{N}\\left(x^{(i)} ; \\mu_2, \\sigma_2^2\\right)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37566f7-f633-41c5-8f4e-2b1415182ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm_dist(x, mu, sigma_2):\n",
    "    P = 1/(np.sqrt(2*np.pi*sigma_2)) * np.exp(-1/(2*sigma_2) * (x-mu)**2)\n",
    "    return P\n",
    "    \n",
    "def post_prob(x, p, mu, sigma_2, i, j):\n",
    "    num_p_j_i = p[j]*norm_dist(x[i], mu[j], sigma_2[j])\n",
    "    den = p[0]*norm_dist(x[i], mu[0], sigma_2[0]) + p[1]*norm_dist(x[i], mu[1], sigma_2[1])\n",
    "    post_prob = num_p_j_i/den\n",
    "    return post_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce90576a-6b40-403d-a147-1e5a2534d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log-likelihood of the data is: -24.5\n"
     ]
    }
   ],
   "source": [
    "# --- Log-Likelihood Calculation ---\n",
    "\n",
    "log_likelihood = 0\n",
    "# Loop through each data point\n",
    "for i in range(len(x)):\n",
    "    # Calculate the likelihood for the current data point x[i]\n",
    "    # This is the sum of probabilities from each Gaussian component\n",
    "    likelihood_i = pi[0] * norm_dist(x[i], mu[0], sigma_2[0]) + \\\n",
    "                   pi[1] * norm_dist(x[i], mu[1], sigma_2[1])\n",
    "    \n",
    "    log_likelihood += np.log(likelihood_i)\n",
    "\n",
    "print(f\"The log-likelihood of the data is: {log_likelihood:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dca42-6186-4f70-bbd7-b7457a043b4b",
   "metadata": {},
   "source": [
    "### E-Step\n",
    "What is the formula for $p(y = k \\mid x, \\theta )$? \n",
    "\n",
    "\\begin{equation}\n",
    "P\\left(y=k \\mid x_i, \\Theta\\right)=\\frac{\\pi_k \\mathcal{N}\\left(x \\mid \\mu_k, \\Sigma_k\\right)}{\\sum_{j=1}^K \\pi_j \\mathcal{N}\\left(x_i \\mid \\mu_j, \\Sigma_j\\right)} .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P\\left(y=k \\mid x_i, \\Theta\\right)=\\frac{\\pi_k N_k}{ \\pi_1 N_1 + \\pi_2 N_2} .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07d2da7d-c874-446f-8622-db14ce44fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 0 Gaussian 2\n",
      "x = 1 Gaussian 2\n",
      "x = 2 Gaussian 2\n",
      "x = 3 Gaussian 1\n",
      "x = 4 Gaussian 1\n"
     ]
    }
   ],
   "source": [
    "# x[0]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if post_prob(x, pi, mu, sigma_2, i, 1) > post_prob(x, pi, mu, sigma_2, i, 0):\n",
    "        print(f\"x = {i} Gaussian {2}\")\n",
    "    else:\n",
    "        print(f\"x = {i} Gaussian {1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b804656-f53a-4443-a47b-1f73b41b2eb4",
   "metadata": {},
   "source": [
    "### M-Step\n",
    "Fixing $p(y = k \\mid x, \\theta _0)$, we want to update $\\theta$ such that our lower bound is maximized.\n",
    "\n",
    "What is the optimal $\\hat{\\mu }_ k$?\n",
    "\n",
    "\\begin{equation}\n",
    "N_k=\\sum_{i=1}^n \\gamma_{i, k}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi_k=\\frac{N_k}{n}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_k^{\\text {new }}=\\frac{1}{N_k} \\sum_{i=1}^n \\gamma_{i, k} x_i .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mu_k}=\\frac{1}{\\sum_{i=1}^n \\gamma_{i, k}} \\sum_{i=1}^n \\gamma_{i, k} x_i .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma_k} = \\frac{1}{\\sum_{i=1}^n \\gamma_{i, k}} \\sum_{i=1}^n \\gamma_{i, k}\\left(x_i-\\hat{\\mu_k}\\right)\\left(x_i-\\hat{\\mu_k}\\right)^T .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma_k} = \\frac{1}{\\sum_{i=1}^n \\gamma_{i, k}} \\sum_{i=1}^n \\gamma_{i, k}\\left(x_i-\\hat{\\mu_k}\\right)^2 .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi_k=\\frac{\\sum_{i=1}^n \\gamma_{i, k}}{n}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afc8a8-342a-49f6-af92-07e330c46754",
   "metadata": {},
   "source": [
    "### Training 1\n",
    "In the first M-step, which Gaussian will shift to the left more (relatively)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08dd269-0ae8-4c76-b579-be28200c161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effective cluster 1 size: 1.8151852969722184\n",
      "effective cluster 1 size: 3.1848147030277816\n",
      "New mean 1: 5.131728029552676\n",
      "Old mean 1: 6 - New mean 1: 5.131728029552676\n",
      "Old mean 2: 7 - New mean 2: 1.4710314946241008\n"
     ]
    }
   ],
   "source": [
    "N_1 = 0\n",
    "for i in range(len(x)):\n",
    "    N_1 += post_prob(x, pi, mu, sigma_2, i, 0)\n",
    "print(f\"effective cluster 1 size: {N_1}\")\n",
    "\n",
    "N_2 = 0\n",
    "for i in range(len(x)):\n",
    "    N_2 += post_prob(x, pi, mu, sigma_2, i, 1)\n",
    "print(f\"effective cluster 1 size: {N_2}\")\n",
    "\n",
    "sum_mu = 0\n",
    "for i in range(len(x)):\n",
    "    sum_mu += post_prob(x, pi, mu, sigma_2, i, 0) * x[i]\n",
    "mu_1_new = sum_mu/N_1 \n",
    "print(f\"New mean 1: {mu_1_new}\")\n",
    "\n",
    "sum_mu = 0\n",
    "for i in range(len(x)):\n",
    "    sum_mu += post_prob(x, pi, mu, sigma_2, i, 1) * x[i]\n",
    "mu_2_new = sum_mu/N_2 \n",
    "\n",
    "print(f\"Old mean 1: {mu[0]} - New mean 1: {mu_1_new}\")\n",
    "print(f\"Old mean 2: {mu[1]} - New mean 2: {mu_2_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb7f0a-43ef-44dd-838a-9d09bd5dd84c",
   "metadata": {},
   "source": [
    "Answer mean 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c2aa8-a88a-4757-a72f-be6d5a15b4f4",
   "metadata": {},
   "source": [
    "### Training 2\n",
    "In the first M-step, which Gaussian's variance will increase more (relatively)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b39e2b9-2dbb-4d42-9943-1458049774ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old variance 1: 1 - New variance 1: 0.615562501441774\n",
      "Old variance 2: 4 - New variance 2: 6.967022101798352\n"
     ]
    }
   ],
   "source": [
    "sum_sigma = 0\n",
    "for i in range(len(x)):\n",
    "    sum_sigma += post_prob(x, pi, mu, sigma_2, i, 0) * (x[i] - mu_1_new)**2\n",
    "sigma_2_1_new = sum_sigma/N_1 \n",
    "\n",
    "sum_sigma = 0\n",
    "for i in range(len(x)):\n",
    "    sum_sigma += post_prob(x, pi, mu, sigma_2, i, 1) * (x[i] - mu_2_new)**2\n",
    "sigma_2_2_new = sum_sigma/N_2 \n",
    "\n",
    "\n",
    "print(f\"Old variance 1: {sigma_2[0]} - New variance 1: {sigma_2_1_new}\")\n",
    "print(f\"Old variance 2: {sigma_2[1]} - New variance 2: {sigma_2_2_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4334d6ac-1773-408d-ae7d-1b10df16fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_size(x, pi, mu, sigma_2, k):\n",
    "    N_k = 0\n",
    "    for i in range(len(x)):\n",
    "        N_k += post_prob(x, pi, mu, sigma_2, i, k)\n",
    "    return N_k.item()\n",
    "\n",
    "def update_pi(x, N_k):\n",
    "    pi_k = N_k/len(x)\n",
    "    return pi_k\n",
    "    \n",
    "def update_mu(x, pi, mu, sigma_2, k, N_k):\n",
    "    sum_mu = 0\n",
    "    for i in range(len(x)):\n",
    "        sum_mu += post_prob(x, pi, mu, sigma_2, i, k) * x[i]\n",
    "    mu_k_new = sum_mu/N_k \n",
    "\n",
    "    return mu_k_new.item()\n",
    "\n",
    "def update_sigma_2(x, pi, mu, sigma_2, k, N_k, mu_k_new):\n",
    "    sum_sigma = 0\n",
    "    for i in range(len(x)):\n",
    "        sum_sigma += post_prob(x, pi, mu, sigma_2, i, 0) * (x[i] - mu_k_new)**2\n",
    "        sigma_2_k_new = sum_sigma/N_k \n",
    "    return sigma_2_k_new.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bc3df83-52ac-4fcf-9db1-03ba202fb499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.5]] [[6, 7]] [[1, 4]]\n"
     ]
    }
   ],
   "source": [
    "pi_array = [pi]\n",
    "mu_array = [mu]\n",
    "sigma_2_array = [sigma_2]\n",
    "\n",
    "print(pi_array, mu_array, sigma_2_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "660bdd7e-664c-4604-825d-71468cabbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    cluster_size_j = []\n",
    "    pi_k = []\n",
    "    mu_k = []\n",
    "    sigma_2_k = []\n",
    "    for k in range(2):\n",
    "        cluster_size_j.append(compute_cluster_size(x, pi_array[epoch], mu_array[epoch], sigma_2_array[epoch], k))\n",
    "        pi_k.append(update_pi(x, cluster_size_j[k]))\n",
    "        mu_k.append(update_mu(x, pi_array[epoch], mu_array[epoch], sigma_2_array[epoch], k, cluster_size_j[k]))\n",
    "        sigma_2_k.append(update_sigma_2(x, pi_array[epoch], mu_array[epoch], sigma_2_array[epoch], k, cluster_size_j[k], mu_k[k]))\n",
    "    \n",
    "    \n",
    "    pi_array.append(pi_k)\n",
    "    mu_array.append(mu_k)\n",
    "    sigma_2_array.append(sigma_2_k)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8703b2a-3588-4057-9f1a-74197474957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    4.  ]\n",
      " [ 0.62  7.99]\n",
      " [ 0.6  12.8 ]\n",
      " [ 0.62 16.11]\n",
      " [ 0.63 18.45]\n",
      " [ 0.64 19.91]\n",
      " [ 0.64 20.73]\n",
      " [ 0.64 21.16]\n",
      " [ 0.64 21.37]\n",
      " [ 0.64 21.48]\n",
      " [ 0.64 21.53]]\n"
     ]
    }
   ],
   "source": [
    "sigma_2_array = np.array(sigma_2_array)\n",
    "print(np.round(sigma_2_array, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807b8a9-f6a4-47c4-86de-391b42196219",
   "metadata": {},
   "source": [
    "No se por qué dice que la varianza 1 es la que mas se incrementa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bfb30-30b4-4cbc-ae19-a293f8ccbe33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
